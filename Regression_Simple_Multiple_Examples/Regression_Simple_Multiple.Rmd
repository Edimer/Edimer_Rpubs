---
title: "Análisis de Regresión con R"
subtitle: "Comparación de modelos de regresión con R"
author: "Edimer David Jaramillo"
output:
  html_notebook:
    toc: true
    css: css/estilo.css
    theme: cosmo
    highlight: zenburn
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE,
                      fig.align = "center",
                      fig.width = 8.5,
                      fig.height = 5)
```

<img src="img/science.png" style="position:absolute;top:0px;right:30px; width:150px" />

# Artículo científico

<center>
<img src = "img/paper.png" />
</center>

# Datos

- Datos tomados del artículo referenciado previamente.
- [Fuente de datos - Artículo en PLOS | ONE.](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0225413#pone-0225413-g001)
- En la base de datos se tienen dos grupos bajo análisis:
    - **Grupo *Long jumpers*:** id 1 a 23.
    - **Grupo *untrained men*:** id 24-45.

# Lectura de datos

```{r}
library(readxl)
library(tidyverse)
datos <- read_xlsx("../data/Data_Paper_Plos_One_Muscle.xlsx", skip = 3,
                   na = "N/A", n_max = 47) %>% 
  rename(RA_takeof_leg = RA...7,
         OB_takeof_leg = OB...8,
         PM_takeof_leg = PM...9,
         QL_takeof_leg = QL...10,
         ES_takeof_leg = ES...11,
         Gmax_takeof_leg = Gmax...12,
         Gmed_takeof_leg = Gmed...13,
         IL_takeof_leg = IL...14,
         RA_free_leg = RA...15,
         OB_free_leg = OB...16,
         PM_free_leg = PM...17,
         QL_free_leg = QL...18,
         ES_free_leg = ES...19,
         Gmax_free_leg = Gmax...20,
         Gmed_free_leg = Gmed...21,
         IL_free_leg = IL...22,
         id = ID,
         edad = `Age (years)`,
         altura_cm = `Height (cm)`,
         imc = `Body mass (kg)`,
         dist_salto_cm = `long jump distance (cm)`,
         sprint_100m_seconds = `100-m sprint time (s)`,
         grasa_subcut_cm2 = `Subcutaneous fat CSA (absolute value, cm2)`) %>% 
  mutate(type = if_else(id %in% c(1:23), true = "Long jumpers",
                        false = "Untrained men"))
datos
```

# Objetivos

- Replicar análisis estadísticos aplicados en el artículo científico de interés.
- Evidenciar la relación existente entre características anatómicas de atletas vs rendimiento en salto largo.
- Evaluar otros métodos de [*statistical learning*](https://edimer.github.io/documents_R/LinearModels_LeastSquares/LinearModels_LeastSqauares.html#1) y compararlos con los resultados obtenidos por los autores.

# Resultados del *paper* 

## Correlaciones 

- Aunque fueron numerosos los resultados obtenidos por los autores, para el objetivo de este documento se destacan los siguientes:
    - La relación entre el área transversal relativa (CSA) del recto abdominal (AR) del lado de la pierna de despegue y el mejor registro personal para el salto largo.
        - **Correlación:** 0.674
        - **Valor p:** 0.004 (estadísticamente significativo)

- Las correlaciones (con intervalo de confianza del 95%) se presentan en la siguiente tabla:

<center>
<img src = "img/correlations.png"/>
</center>

## Gráfico de dispersión {.tabset .tabset-fade .tabset-pills}

### Original

<center>
<img src = "img/paper2.png" width="400" />
</center>

### Réplica con R

```{r}
library(ggplot2)
datos %>% 
  ggplot(data = ., aes(x = RA_takeof_leg, y = dist_salto_cm)) +
  geom_point(size = 3) +
  labs(x = expression('Relative CSA of RA takeoff leg side - cm'^"2"/'kg'^"2/3"),
       y = "Personal best record of long jump (cm)") +
  geom_smooth(method = "lm", se = FALSE, lty = 3, lwd = 1, color = "black") +
  theme_light()
```

## Predichos vs Reales (*paper*)

<center>
<img src = "img/paper3.png" width="400" />
</center>

# Resultados adicionales con R

## Distribuciones

```{r, fig.height=10}
datos %>% 
  select_if(is.numeric) %>% 
  select(-id) %>% 
  gather(key = "variable", value = "valor") %>% 
  ggplot(data = ., aes(x = valor)) +
  facet_wrap(facets = ~variable, scales = "free", ncol = 4) +
  geom_histogram(aes(y = ..density..), bins = 10, color = "black", 
                 fill = "gray60") +
  geom_density(fill = "gray50", alpha = 0.18) +
  geom_rug() +
  labs(x = "", y = "Densidad") +
  theme_light() +
  theme(strip.background = element_rect(fill = "deepskyblue4"),
        strip.text = element_text(color = "black"))
```

## Gráficos cuantil cuantil

```{r, fig.height=10}
library(qqplotr)
datos %>% 
  select_if(is.numeric) %>% 
  select(-id) %>% 
  gather(key = "variable", value = "valor") %>% 
  ggplot(data = ., aes(sample = valor)) +
  facet_wrap(facets = ~variable, scales = "free", ncol = 4) +
  geom_qq_band(fill = "gray25") +
  stat_qq_line(color = "darkgreen") +
  stat_qq_point(color = "black", size = 0.8) +
  labs(x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
  theme_light() +
  theme(strip.background = element_rect(fill = "deepskyblue4"),
        strip.text = element_text(color = "black"))
```

## Comparativos

- Se comparan registros  de *cross-sectional area (CSA)* de la pierna de despeque (*takeoff*) vs la pierna libre (*free*). Las variables (músculos) a comparar son las siguientes:
    - **RA:** recto abdominal.
    - **OB:** oblicuos internos y externos.
    - **PM:** psoas mayor.
    - **QL:** cuadrado lumbar.
    - **ES:** erector *spinae*.
    - **Gmax:** gluteo mayor.
    - **Gmed:** gluteos medio y mínimo.
    - **IL:** iliaco

```{r, fig.height=5.5}
df_takeoff_leg <- datos %>% 
  select(RA_takeof_leg:IL_takeof_leg) %>% 
  gather(key = "variable", value = "valor") %>% 
  mutate(tipo = "TakeoffLeg")

df_free_leg <- datos %>% 
  select(RA_free_leg:IL_free_leg) %>% 
  gather(key = "variable", value = "valor") %>% 
  mutate(tipo = "FreeLeg")

df_takeoff_free <- df_takeoff_leg %>% 
  bind_rows(df_free_leg)

df_takeoff_free %>% 
  separate(col = variable, into = c("variable", "v1", "v2")) %>% 
  select(-c(v1, v2))  %>% 
  ggplot(data = ., aes(x = tipo, y = valor, fill = tipo)) +
  facet_wrap(facets = ~variable, scales = "free", ncol = 4) +
  geom_boxplot(color = "black") +
  scale_fill_manual(values = c("darkgreen", "gold4")) +
  labs(x = "Tipo de pierna", y = "") +
  theme_light() +
  theme(strip.background = element_rect(fill = "deepskyblue4"),
        strip.text = element_text(color = "black"),
        legend.position = "none")
```

## Shapiro Wilk

Se comprueba la normalidad de las variables ($\alpha = 0.05$), bajo el siguiente juego de hipótesis:

$$H_0: X \sim N(\mu, \sigma^2)\\
H1: x \nsim N(\mu, \sigma^2)$$

```{r}
datos %>% 
  select_if(is.numeric) %>% 
  select(-id) %>% 
  gather(key = "variable", value = "valor") %>% 
  group_by(variable) %>% 
  summarise(valor = list(valor)) %>% 
  ungroup() %>% 
  group_by(variable) %>% 
  mutate(shapiro_valorP = round(shapiro.test(unlist(valor))$p.value, digits = 5),
         Resultado = if_else(shapiro_valorP <= 0.05, true = "No normalidad",
                             false = "Sí normalidad"))  %>% 
  select(-valor)
```

- <tred>**Nota:**</tred> aunque los autores mencionan que fueron aplicadas las pruebas de *Shapiro Wilk* para comprobar el supuesto de normalidad, en la tabla anterior se evidencia que algunas variables (*ej.*  distancia de salto, grasa subcutanea, entre otras) no se distribuyen de forma normal. Este resultado tiene connotaciones de importancia, ya que las correlaciones podrían ser obtenidas mediante métodos *no paramétricos*.
    
## Matriz de correlaciones

- Se construye la matriz de correlaciones (método de *Pearson*).
- La variable que presente mayor correlación lineal con la longitud del salto, será tenida en cuenta para estructurar el *modelo de regresión lineal simple (RLS)*. Con las demás variables se construye el *modelo de regresión lineal múltiple (RLM)*.
    
```{r, fig.width=9, fig.height=8}
library(corrplot)
library(RColorBrewer)
datos %>% 
  select_if(is.numeric) %>% 
  select(-id) %>% 
  cor(use = "complete.obs") %>% 
  corrplot(method = "pie",
           type = "upper",
           diag = FALSE,
           tl.cex = 0.8,
           tl.srt = 45,
           addgrid.col = "black",
           order = "hclust",
           col = brewer.pal(n = 10, name = "Spectral"))
```
    
- <tred>**Notas:**</tred> 
    - Se evidencia alta correlación entre algunas variables. Este patrón sugiere problemas de *multicolinealidad* al ajustar un modelo de *RLM*.
    - Atletas con mayor altura tienden a presentar saltos de menor distancia. Este comportamiento es obtenido de igual forma en aquellos que aumentan la velocidad del *sprint* al saltar, es decir, que a mayor velocidad, menor longitud de salto.
    - Atletas con el músculo recto abdominal de mayor longitud, presentan mayores distancias en sus saltos. Con esta variable se ajusta el modelo de *RLS*.
    
# Regresión Lineal Simple (RLS) {.tabset .tabset-fade .tabset-pills}

- Se propone cuantificar la unidad de cambio en la distancia del salto vs la longitud (cm^2^/kg^2/3^) del músculo recto abdominal (RA), para la pierna de despegue (*takeoff*).
- El modelo de *RLS* puede ser expresado de la siguiente manera:
$$Y = \beta_0\ + \beta_1X \\
\hat{Y} = \hat{\beta_0}\ + \hat{\beta_1}X\ + \epsilon$$
- Escrito de cara al fenómeno bajo estudio, el modelo queda expresado como sigue:
$$Distancia = \hat{\beta_0}\ + (\hat{\beta_1}\times RA) + \epsilon$$
- Este modelo de *RLS* es ajustado a través del [*Método de Mínimos Cuadrados.*](https://edimer.github.io/documents_R/LinearModels_LeastSquares/LinearModels_LeastSqauares.html#1)

## Modelo Lineal con `lm()`

```{r}
mod_rls <- lm(dist_salto_cm ~ RA_takeof_leg, data = datos)
summary(mod_rls)
```

- <tred>**Nota:**</tred> el resultado anterior sugiere que la variable `RA_takeof_leg` es estadísticamente significativa ($valor\ p =0.0139$) sobre la variabilidad observada en la distancia del salto. Además, se puede inferir que por cada unidad que aumenta `RA_takeof_leg`, la distancia de salto es 11.928 centímetros mayor. La variable `RA_takeof_leg` explica 22.01% de la variabilidad observada en la distancia de salto.

## Significancia Estadística

```{r}
anova(mod_rls)
```

## Residuales

```{r}
par(mfrow = c(2, 2))
plot(mod_rls)
```

- **Normalidad (Shapiro Wilk) de los residuales:** 

```{r}
shapiro.test(residuals(mod_rls))
```

- **Heterocedasticidad - [*Breusch Pagan Test*](https://es.wikipedia.org/wiki/Test_de_Breusch-Pagan):**

```{r}
library(lmtest)
bptest(mod_rls)
```

- **Autocorrelación - *[Test de Durbi Watson](https://es.wikipedia.org/wiki/Estad%C3%ADstico_de_Durbin-Watson)*:**

```{r}
dwtest(mod_rls)
```

- Se comprueba que existe normalidad de los residuos, son homocedasticos y no existe autocorrelación de los mismos.

## Reales vs Predichos

```{r}
reales <- datos$dist_salto_cm[!is.na(datos$dist_salto_cm)]
predichos_rls <- mod_rls$fitted.values
data.frame(
  Real = reales,
  Predichos = predichos_rls
) %>% 
  ggplot(data = ., aes(x = Predichos, y = Real)) +
  geom_point() +
  labs(x = ("Valores predichos de distancia (cm)"),
       y = "Valores reales de distancia (cm)") +
  geom_smooth(method = "lm", se = FALSE, lty = 3, lwd = 1, color = "black") +
  theme_light()
```

- La correlación entre los **valores reales** y **valores predichos** por el modelo de *RLS* es: `r round(cor(reales, predichos_rls), digits = 3)`; más baja que la reportada por los autores al ajustar un modelo de *RLM*, cuyo valor es igual a 0.892

# Regresión Lineal Múltiple (RLM) {.tabset .tabset-fade .tabset-pills}

- Para la construcción del modelo de *RLM* se comprueba la multicolinealidad de las variables y se proponen cuatro alternativas:
    - <tred>**Modelo 0 (sobreparametrizado):**</tred> modelo con todas las variables incluidas como predictoras.
    - <tred>**Modelo 1:**</tred> Modelo de *RLM* con eliminación de variables por valores de correlación y [*factor inflacionario de varianza - VIF.*](https://es.wikipedia.org/wiki/Factor_de_inflaci%C3%B3n_de_la_varianza).
    - <tred>**Modelo 2:**</tred> Modelo de *RLM* con eliminación de variables por *VIF* a través del método *Stepwise* (utilizado por los autores del artículo).
    - <tred>**Modelo 3:**</tred> Modelo de regresión por componentes principales ([*mínimos cuadrados parciales*](https://en.wikipedia.org/wiki/Partial_least_squares_regression)).
- Los modelos son comparados a través del *R^2^ ajustado* (mayor mejor) y el *cuadrado medio del error (CME).*

## Modelo 0

```{r}
mod_rlm0 <- lm(dist_salto_cm ~ .,
               data = datos %>% select_if(is.numeric) %>% select(-id))
summary(mod_rlm0)
```

- El R^2^ ajustado es próximo a 1, sin embargo, pocas variables independientes (predictoras) son estadísticamente significativas ($p<0.05$), patron de comportamiento que sugiere problemas de multicolinealidad. La siguiente gráfica muestra anomalías en los residuales del modelo.

```{r}
par(mfrow = c(2, 2))
plot(mod_rlm0)
```

- Estos resultados evidencian que el modelo ajustado no es adecuado para explicar la variabilidad observada en la distancia de salto. Es importante resaltar que el R^2^ no es la mejor medida de bondad de ajuste, ya que éste aumenta en función del número de predictores.

```{r}
# Valores predichos por mod_rlm0
predichos_rlm0 <- mod_rlm0$fitted.values 
```

## Modelo 1

- Selección de predictores teniendo en cuenta valores iguales o inferiores a 0.70 de correlación. La selección es posible con la bibliteca [`usdm`](https://cran.r-project.org/web/packages/usdm/usdm.pdf) que posee funciones flexibles para diagnósticos de multicolinealidad.

```{r}
# Variables predictoras
df_predictoras <-datos %>%
  select_if(is.numeric) %>% dplyr::select(-c(id, dist_salto_cm)) %>% 
  as.matrix()

library(usdm)
vifcor(x = df_predictoras, th = 0.70)
```

- Este resultado muestra que de las 21 variables consideradas en el modelo inicial (*modelo 0*) 10 de ellas presentan problemas de colinealidad. Tomando un límite de 0.70 de correlación como criterio de exclusión de predictores, la correlación máxima presente en las variables seleccionadas, es de 0.68. La tabla anterior muestra los predictores que podrían hacer parte del modelo.

- **Nuevo modelo:**

```{r}
mod_rlm1 <- lm(dist_salto_cm ~ edad + altura_cm + sprint_100m_seconds
               + QL_takeof_leg + IL_takeof_leg + RA_free_leg + OB_free_leg
               + PM_free_leg + Gmed_free_leg + IL_free_leg + grasa_subcut_cm2,
               data = datos)
summary(mod_rlm1)
```

- El R^2^ ajustado es igual a 0.5936 y sólo son estadísticamente significativas las variables altura y sprint. En general, el modelo es estadísticamente significativo ($p = 0.01622$) para explicar la variabilidad en la distancia de salto. 

```{r}
# Valores predichos por mod_rlm1
predichos_rlm1 <- mod_rlm1$fitted.values
```

## Modelo 2

- Son excluidas variables que presenten *VIF* por encima de 10.

```{r}
vifstep(x = df_predictoras, th = 10)
```

- Este método de selección arroja que 6 de las 21 variables totales (`mod_rlm0`) tienen problemas de colinealidad. El modelo considera 15 variables como independientes, con valores máximos de *VIF* que no superan 9.64.

- **Nuevo modelo:**

```{r}
mod_rlm2 <- lm(dist_salto_cm ~ edad + altura_cm + sprint_100m_seconds
               + QL_takeof_leg + IL_takeof_leg + RA_free_leg + OB_free_leg
               + PM_free_leg + Gmed_free_leg + IL_free_leg + grasa_subcut_cm2
               + ES_takeof_leg + Gmed_takeof_leg + QL_free_leg + Gmax_free_leg,
               data = datos)
summary(mod_rlm2)
```

- El R^2^ ajustado es igual a 0.5486 y sólo son estadísticamente significativas las variables altura y sprint. En general, el modelo no es estadísticamente significativo ($p = 0.08803$) para explicar la variabilidad en la distancia de salto. Dado que aún hay presencia de un número elevado de predictores, se construye el modelo final luego de aplicar el método *Stepwise*, basado en el [*Criterio de Información de Akaike*](https://en.wikipedia.org/wiki/Akaike_information_criterion).

```{r}
mod_rlm2.1 <- step(object = mod_rlm2, direction = "both")
```

- Este método sugiere que el mejor modelo alcanza un valor mínimo de *AIC* igual a 153.83, cuando son consideradas las variables altura, sprint, IL_takeoff, RA_free, Gmed_free, IL_free, ES_takeoff y Gmed_takeoff. Son estadísticamente significativas la altura, sprint, IL_takeoff y RA_free; con R^2^ ajustado igual a 0.7186 (<tred>cercano al valor (0.763) reportado por los autores en el paper</tred>).

```{r}
summary(mod_rlm2.1)
```


```{r}
# Valores predichos con mod_rlm2.1
predichos_rlm2 <- mod_rlm2.1$fitted.values
```


## Modelo 3

# Anexos

## Biblioteca `car`

- Con la biblioteca `car`, haciendo uso de la función vif, es posible conocer los valores del *Factor de Inflación de Varianza*.

```{r}
library(car)
vif(mod_rlm0)   # Aplicado sobre modelo sobreparametrizado
```

- Estos mismos valores se pueden obtener manualmente con la diagonal de la inversa de la matriz de correlaciones.

```{r}
# Matriz de correlaciones
mtx_cor <- cor(df_predictoras, use = "complete.obs")

# Inversa de mtx_cor
inversa_cor <- solve(mtx_cor)

# VIFs
diag(inversa_cor)
```

## Biblioteca `mctest`

- Con la biblioteca `mctest` es posible graficar los *VIFs* y valores propios (*Eigen Values*).

```{r}
library(mctest)
mc.plot(x = df_predictoras, y = datos$dist_salto_cm, vif = 10)
```

- El gráfico anterior puede ser construido manualmente con el siguiente código:

```{r}
data.frame(
  variable = names(diag(inversa_cor)),
  VIF      = diag(inversa_cor)
) %>% 
  ggplot(data = ., aes(x = variable, y = VIF)) +
  geom_point() +
  geom_hline(yintercept = 10, color = "red", lty = 2) +
  labs(x = "Variable", y = "VIF",
       title = "Factor Inflacionario de Varianza (VIF)") +
  theme_light() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, color = "black"),
        axis.text.y = element_text(color = "black"))
```

